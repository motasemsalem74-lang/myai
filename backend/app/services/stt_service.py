"""
ุฎุฏูุฉ ุชุญููู ุงูุตูุช ุฅูู ูุต (STT)
Speech-to-Text Service using Whisper
"""

import os
import base64
import asyncio
import logging
from typing import Dict, Any, Optional
from pathlib import Path
import uuid
import json

logger = logging.getLogger(__name__)

class STTService:
    """ุฎุฏูุฉ ุชุญููู ุงูุตูุช ุฅูู ูุต"""
    
    def __init__(self):
        self.whisper_api_key = os.getenv("WHISPER_API_KEY")
        self.local_model = os.getenv("LOCAL_WHISPER_MODEL", "base")
        self.use_local = not bool(self.whisper_api_key)
        self.temp_audio_dir = Path(os.getenv("TEMP_AUDIO_DIR", "./temp_audio"))
        
        self.temp_audio_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"โ STT Service initialized (Mode: {'Local' if self.use_local else 'API'})")
    
    async def speech_to_text(
        self,
        audio_data: str,
        language: str = "ar",
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ุชุญููู ุงูุตูุช ุฅูู ูุต
        
        Args:
            audio_data: ุจูุงูุงุช ุงูุตูุช (base64)
            language: ุงููุบุฉ (ar ููุนุฑุจูุฉ)
            user_id: ูุนุฑู ุงููุณุชุฎุฏู (ุงุฎุชูุงุฑู)
        
        Returns:
            Dict ูุญุชูู ุนูู ุงููุต ูุงูุจูุงูุงุช ุงูุฅุถุงููุฉ
        """
        
        try:
            # ุญูุธ ุงูููู ุงูุตูุชู ูุคูุชุงู
            audio_path = await self._save_temp_audio(audio_data, user_id)
            
            # ุชุญููู ุงูุตูุช ุฅูู ูุต
            if self.use_local:
                result = await self._transcribe_local(audio_path, language)
            else:
                result = await self._transcribe_api(audio_path, language)
            
            # ุญุฐู ุงูููู ุงููุคูุช
            await self._cleanup_temp_file(audio_path)
            
            return {
                "success": True,
                "text": result["text"],
                "language": result.get("language", language),
                "confidence": result.get("confidence", 0.9),
                "duration": result.get("duration", 0),
                "segments": result.get("segments", [])
            }
            
        except Exception as e:
            logger.error(f"โ Error in STT: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "text": ""
            }
    
    async def _save_temp_audio(self, audio_base64: str, user_id: Optional[str]) -> Path:
        """ุญูุธ ุงูููู ุงูุตูุชู ูุคูุชุงู"""
        
        file_id = uuid.uuid4().hex[:8]
        filename = f"temp_audio_{user_id or 'unknown'}_{file_id}.wav"
        audio_path = self.temp_audio_dir / filename
        
        # ูู ุชุดููุฑ base64 ูุญูุธ
        audio_bytes = base64.b64decode(audio_base64)
        audio_path.write_bytes(audio_bytes)
        
        logger.info(f"๐พ Saved temp audio: {audio_path}")
        
        return audio_path
    
    async def _transcribe_local(self, audio_path: Path, language: str) -> Dict[str, Any]:
        """ุชุญููู ุงูุตูุช ุฅูู ูุต ุจุงุณุชุฎุฏุงู ูููุฐุฌ ูุญูู (Whisper)"""
        
        try:
            logger.info(f"๐ค Transcribing audio locally with model: {self.local_model}")
            
            # ูู ุงูุชุทุจูู ุงูุญููููุ ูุชู ุงุณุชุฎุฏุงู:
            # import whisper
            # model = whisper.load_model(self.local_model)
            # result = model.transcribe(str(audio_path), language=language)
            
            # ูุญุงูุงุฉ ุงููุนุงูุฌุฉ
            await asyncio.sleep(1.0)
            
            # ูุต ุชุฌุฑูุจู
            sample_text = "ูุฑุญุจุงูุ ูุฐุง ูุต ุชุฌุฑูุจู ูู ูููุฐุฌ Whisper ุงููุญูู"
            
            return {
                "text": sample_text,
                "language": language,
                "confidence": 0.92,
                "duration": 3.5,
                "segments": [
                    {
                        "start": 0.0,
                        "end": 3.5,
                        "text": sample_text,
                        "confidence": 0.92
                    }
                ]
            }
            
        except Exception as e:
            logger.error(f"โ Error in local transcription: {e}")
            raise
    
    async def _transcribe_api(self, audio_path: Path, language: str) -> Dict[str, Any]:
        """ุชุญููู ุงูุตูุช ุฅูู ูุต ุจุงุณุชุฎุฏุงู Whisper API"""
        
        try:
            import httpx
            
            logger.info(f"๐ Transcribing audio via Whisper API")
            
            # ูุฑุงุกุฉ ุงูููู
            audio_bytes = audio_path.read_bytes()
            
            # ุงุณุชุฏุนุงุก Whisper API
            async with httpx.AsyncClient(timeout=60.0) as client:
                files = {
                    "file": (audio_path.name, audio_bytes, "audio/wav"),
                    "model": (None, "whisper-1"),
                    "language": (None, language)
                }
                
                headers = {
                    "Authorization": f"Bearer {self.whisper_api_key}"
                }
                
                response = await client.post(
                    "https://api.openai.com/v1/audio/transcriptions",
                    files=files,
                    headers=headers
                )
                
                response.raise_for_status()
                result = response.json()
                
                return {
                    "text": result["text"],
                    "language": language,
                    "confidence": 0.95,
                    "duration": result.get("duration", 0)
                }
                
        except Exception as e:
            logger.error(f"โ Error in API transcription: {e}")
            raise
    
    async def _cleanup_temp_file(self, file_path: Path):
        """ุญุฐู ุงูููู ุงููุคูุช"""
        
        try:
            if file_path.exists():
                file_path.unlink()
                logger.info(f"๐๏ธ Deleted temp file: {file_path}")
        except Exception as e:
            logger.warning(f"โ๏ธ Could not delete temp file: {e}")
    
    async def transcribe_stream(
        self,
        audio_stream,
        language: str = "ar",
        callback=None
    ) -> Dict[str, Any]:
        """
        ุชุญููู ูุฌุฑู ุตูุชู (streaming) ุฅูู ูุต
        ูููุฏ ููููุงููุงุช ุงูุญูุฉ
        """
        
        try:
            logger.info("๐ด Starting streaming transcription")
            
            full_transcript = ""
            segments = []
            
            # ูุนุงูุฌุฉ ุงููุฌุฑู
            async for chunk in audio_stream:
                # ุชุญููู ูู ูุทุนุฉ ุฅูู ูุต
                result = await self.speech_to_text(chunk, language)
                
                if result["success"]:
                    full_transcript += " " + result["text"]
                    segments.append({
                        "text": result["text"],
                        "timestamp": asyncio.get_event_loop().time()
                    })
                    
                    # ุงุณุชุฏุนุงุก callback ููุชุญุฏูุซุงุช ุงูุญูุฉ
                    if callback:
                        await callback(result["text"])
            
            return {
                "success": True,
                "full_transcript": full_transcript.strip(),
                "segments": segments
            }
            
        except Exception as e:
            logger.error(f"โ Error in streaming transcription: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def detect_language(self, audio_data: str) -> Dict[str, Any]:
        """ุงูุชุดุงู ูุบุฉ ุงูุตูุช"""
        
        try:
            # ุญูุธ ุงูููู ูุคูุชุงู
            audio_path = await self._save_temp_audio(audio_data, None)
            
            # ูู ุงูุชุทุจูู ุงูุญูููู:
            # model = whisper.load_model("base")
            # audio = whisper.load_audio(str(audio_path))
            # audio = whisper.pad_or_trim(audio)
            # mel = whisper.log_mel_spectrogram(audio).to(model.device)
            # _, probs = model.detect_language(mel)
            # detected_language = max(probs, key=probs.get)
            
            await asyncio.sleep(0.5)
            
            # ุญุฐู ุงูููู
            await self._cleanup_temp_file(audio_path)
            
            return {
                "success": True,
                "language": "ar",
                "confidence": 0.88,
                "alternatives": [
                    {"language": "ar", "confidence": 0.88},
                    {"language": "en", "confidence": 0.12}
                ]
            }
            
        except Exception as e:
            logger.error(f"โ Error detecting language: {e}")
            return {
                "success": False,
                "error": str(e),
                "language": "unknown"
            }
    
    async def extract_keywords(self, text: str) -> list[str]:
        """ุงุณุชุฎุฑุงุฌ ุงููููุงุช ุงูููุชุงุญูุฉ ูู ุงููุต"""
        
        # ูููุงุช ุงูุฑุจุท ุงูุชู ุณูุชู ุงุณุชุจุนุงุฏูุง
        stop_words = {
            "ูู", "ูู", "ุฅูู", "ุนูู", "ุนู", "ูุน", "ูู", "ูู", "ุฃูุง", "ุฃูุช",
            "ู", "ุฃู", "ููู", "ุซู", "ูุงู", "ูุฐุง", "ุฐูู", "ุงูุชู", "ุงูุฐู"
        }
        
        # ุชูุณูู ุงููุต ุฅูู ูููุงุช
        words = text.split()
        
        # ุชุตููุฉ ุงููููุงุช
        keywords = [
            word.strip(".,!?ุ:")
            for word in words
            if len(word) > 2 and word not in stop_words
        ]
        
        # ุฅุฑุฌุงุน ุงููููุงุช ุงููุฑูุฏุฉ
        return list(set(keywords))[:10]  # ุฃูู 10 ูููุงุช
