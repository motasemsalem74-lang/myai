"""
Ø®Ø¯Ù…Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª (TTS) - Edge TTS
Text-to-Speech Service using Microsoft Edge TTS (Free & Natural!)
"""

import os
import base64
import asyncio
import logging
from typing import Optional, Dict, Any
from pathlib import Path
import uuid

import edge_tts
from app.models.schemas import EmotionType

logger = logging.getLogger(__name__)

class EdgeTTSService:
    """Ø®Ø¯Ù…Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Edge TTS (Ù…Ø¬Ø§Ù†ÙŠ!)"""
    
    def __init__(self):
        # Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØµØ±ÙŠ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
        self.default_voice = os.getenv("TTS_VOICE", "ar-EG-SalmaNeural")
        self.rate = os.getenv("TTS_RATE", "+0%")
        self.volume = os.getenv("TTS_VOLUME", "+0%")
        self.pitch = os.getenv("TTS_PITCH", "+0Hz")
        
        self.temp_audio_dir = Path(os.getenv("TEMP_AUDIO_DIR", "/tmp/temp_audio"))
        self.temp_audio_dir.mkdir(parents=True, exist_ok=True)
        
        # Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©
        self.egyptian_voices = {
            "female": "ar-EG-SalmaNeural",  # Ø³Ù„Ù…Ù‰ - Ø£Ù†Ø«Ù‰
            "male": "ar-EG-ShakirNeural"     # Ø´Ø§ÙƒØ± - Ø°ÙƒØ±
        }
        
        logger.info(f"âœ… Edge TTS Service initialized (Voice: {self.default_voice})")
    
    async def text_to_speech(
        self,
        text: str,
        user_id: Optional[str] = None,
        emotion: EmotionType = EmotionType.NEUTRAL,
        speed: float = 1.0,
        voice_gender: str = "female",
        add_thinking_sounds: bool = False
    ) -> Dict[str, Any]:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Edge TTS
        
        Args:
            text: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­ÙˆÙŠÙ„Ù‡
            user_id: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            emotion: Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            speed: Ø³Ø±Ø¹Ø© Ø§Ù„ÙƒÙ„Ø§Ù… (0.5 - 2.0)
            voice_gender: Ø§Ù„Ø¬Ù†Ø³ ("female" Ø£Ùˆ "male")
            add_thinking_sounds: Ø¥Ø¶Ø§ÙØ© Ø£ØµÙˆØ§Øª Ø§Ù„ØªÙÙƒÙŠØ±
        
        Returns:
            Dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª Ø¨ØµÙŠØºØ© base64
        """
        
        try:
            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
            voice = self.egyptian_voices.get(voice_gender, self.default_voice)
            
            # Ø¥Ø¶Ø§ÙØ© Ø£ØµÙˆØ§Øª Ø§Ù„ØªÙÙƒÙŠØ± Ø¥Ù† Ø·ÙÙ„Ø¨
            if add_thinking_sounds:
                text = self._add_thinking_sounds(text)
            
            # ØªØ·Ø¨ÙŠÙ‚ ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            text, rate_adj, pitch_adj = self._apply_emotion(text, emotion, speed)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª
            audio_path = await self._generate_speech(text, voice, rate_adj, pitch_adj)
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ù€ base64
            audio_bytes = audio_path.read_bytes()
            audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            await self._cleanup_temp_file(audio_path)
            
            return {
                "success": True,
                "audio_base64": audio_base64,
                "duration_seconds": self._estimate_duration(text, speed),
                "format": "mp3",
                "voice": voice
            }
            
        except Exception as e:
            logger.error(f"âŒ Error in TTS: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "audio_base64": None
            }
    
    async def _generate_speech(
        self, 
        text: str, 
        voice: str, 
        rate: str, 
        pitch: str
    ) -> Path:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Edge TTS"""
        
        try:
            logger.info(f"ğŸ”Š Generating speech with voice: {voice}")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ù…Ù„Ù ÙØ±ÙŠØ¯
            file_id = uuid.uuid4().hex[:8]
            output_file = self.temp_audio_dir / f"speech_{file_id}.mp3"
            
            # Ø¥Ù†Ø´Ø§Ø¡ TTS communicate object
            communicate = edge_tts.Communicate(
                text=text,
                voice=voice,
                rate=rate,
                volume=self.volume,
                pitch=pitch
            )
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
            await communicate.save(str(output_file))
            
            logger.info(f"âœ… Speech generated: {output_file}")
            
            return output_file
            
        except Exception as e:
            logger.error(f"âŒ Error generating speech: {e}")
            raise
    
    def _add_thinking_sounds(self, text: str) -> str:
        """Ø¥Ø¶Ø§ÙØ© Ø£ØµÙˆØ§Øª Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©"""
        
        import random
        
        thinking_sounds = [
            "ÙŠØ¹Ù†ÙŠ... ",
            "Ø®Ù„ÙŠÙ†ÙŠ Ø£ÙÙƒØ±... ",
            "Ø·Ø¨... ",
            "Ø¢Ù‡... ",
        ]
        
        # Ø¥Ø¶Ø§ÙØ© ØµÙˆØª ØªÙÙƒÙŠØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø£Ø­ÙŠØ§Ù†Ø§Ù‹
        if random.random() < 0.2:  # 20% Ø§Ø­ØªÙ…Ø§Ù„
            text = random.choice(thinking_sounds) + text
        
        return text
    
    def _apply_emotion(
        self, 
        text: str, 
        emotion: EmotionType, 
        base_speed: float
    ) -> tuple[str, str, str]:
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª"""
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø·Ø¨Ù‚Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        emotion_effects = {
            EmotionType.HAPPY: {
                "rate_adj": 1.1,  # Ø£Ø³Ø±Ø¹ Ù‚Ù„ÙŠÙ„Ø§Ù‹
                "pitch_adj": 5    # Ø£Ø¹Ù„Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹
            },
            EmotionType.SAD: {
                "rate_adj": 0.9,  # Ø£Ø¨Ø·Ø£
                "pitch_adj": -5   # Ø£Ø®ÙØ¶
            },
            EmotionType.EXCITED: {
                "rate_adj": 1.2,  # Ø£Ø³Ø±Ø¹
                "pitch_adj": 8    # Ø£Ø¹Ù„Ù‰
            },
            EmotionType.WORRIED: {
                "rate_adj": 0.95, # Ø£Ø¨Ø·Ø£ Ù‚Ù„ÙŠÙ„Ø§Ù‹
                "pitch_adj": 0    # Ø¹Ø§Ø¯ÙŠ
            },
            EmotionType.NEUTRAL: {
                "rate_adj": 1.0,
                "pitch_adj": 0
            }
        }
        
        effect = emotion_effects.get(emotion, emotion_effects[EmotionType.NEUTRAL])
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        final_speed = base_speed * effect["rate_adj"]
        speed_percent = int((final_speed - 1.0) * 100)
        rate_adj = f"+{speed_percent}%" if speed_percent >= 0 else f"{speed_percent}%"
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        pitch_adj = f"+{effect['pitch_adj']}Hz" if effect['pitch_adj'] >= 0 else f"{effect['pitch_adj']}Hz"
        
        return text, rate_adj, pitch_adj
    
    def _estimate_duration(self, text: str, speed: float) -> float:
        """ØªÙ‚Ø¯ÙŠØ± Ù…Ø¯Ø© Ø§Ù„ØµÙˆØª Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ"""
        
        # Ù…ØªÙˆØ³Ø· Ø³Ø±Ø¹Ø© Ø§Ù„ÙƒÙ„Ø§Ù…: Ø­ÙˆØ§Ù„ÙŠ 150 ÙƒÙ„Ù…Ø© ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
        words = len(text.split())
        base_duration = (words / 150) * 60  # Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø³Ø±Ø¹Ø©
        adjusted_duration = base_duration / speed
        
        return round(adjusted_duration, 2)
    
    async def _cleanup_temp_file(self, file_path: Path):
        """Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª"""
        
        try:
            if file_path.exists():
                file_path.unlink()
                logger.info(f"ğŸ—‘ï¸ Deleted temp file: {file_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ Could not delete temp file: {e}")
    
    async def get_available_voices(self) -> list[Dict[str, str]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        
        try:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø£ØµÙˆØ§Øª
            all_voices = await edge_tts.list_voices()
            
            # ØªØµÙÙŠØ© Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©
            egyptian_voices = [
                {
                    "name": v['ShortName'],
                    "gender": v['Gender'],
                    "locale": v['Locale'],
                    "friendly_name": v.get('FriendlyName', v['ShortName'])
                }
                for v in all_voices
                if v['Locale'].startswith('ar-EG')
            ]
            
            return egyptian_voices
            
        except Exception as e:
            logger.error(f"âŒ Error getting voices: {e}")
            return []
    
    async def test_voice(self, voice_name: str) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± ØµÙˆØª Ù…Ø¹ÙŠÙ†"""
        
        test_text = "Ø£Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ. Ø¥Ø²ÙŠÙƒ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ø©ØŸ"
        
        try:
            audio_path = await self._generate_speech(
                text=test_text,
                voice=voice_name,
                rate=self.rate,
                pitch=self.pitch
            )
            
            audio_bytes = audio_path.read_bytes()
            audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
            
            await self._cleanup_temp_file(audio_path)
            
            return {
                "success": True,
                "audio_base64": audio_base64,
                "text": test_text,
                "voice": voice_name
            }
            
        except Exception as e:
            logger.error(f"âŒ Error testing voice: {e}")
            return {
                "success": False,
                "error": str(e)
            }
