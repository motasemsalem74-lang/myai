# ğŸ¤ Ø¯Ù„ÙŠÙ„ Groq Whisper - ØªØ­ÙˆÙŠÙ„ ØµÙˆØª Ù„Ù†Øµ Ù…Ø¬Ø§Ù†ÙŠ ÙˆØ³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹!

## âœ… Ù„ÙŠÙ‡ GroqØŸ

- âœ… **Ù…Ø¬Ø§Ù†ÙŠ 100%** - Whisper Large v3 Ù…Ø¬Ø§Ù†Ø§Ù‹!
- âœ… **Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹** - Ø£Ø³Ø±Ø¹ Ù…Ù† OpenAI Ø¨Ù€ 10-20 Ù…Ø±Ø©!
- âœ… **Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©** - Whisper Large v3 (Ø£Ø­Ø¯Ø« Ù†Ø³Ø®Ø©)
- âœ… **ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©** - Ø¯Ù‚Ø© Ù…Ù…ØªØ§Ø²Ø© Ù„Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©
- âœ… **Limits Ù…Ø¹Ù‚ÙˆÙ„Ø©:**
  - 14,400 requests/day Ù…Ø¬Ø§Ù†Ø§Ù‹
  - 30 requests/minute
- âœ… **Ø¨Ø¯ÙˆÙ† Ø§Ø´ØªØ±Ø§ÙƒØ§Øª** - API key Ù…Ø¬Ø§Ù†ÙŠ Ù„Ù„Ø£Ø¨Ø¯!

---

## ğŸ†š Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©:

| Ø§Ù„Ù…Ø¹ÙŠØ§Ø± | Groq | OpenAI | Local Whisper |
|---------|------|--------|---------------|
| **Ø§Ù„ØªÙƒÙ„ÙØ©** | Ù…Ø¬Ø§Ù†ÙŠ âœ… | $0.006/Ø¯Ù‚ÙŠÙ‚Ø© ğŸ’° | Ù…Ø¬Ø§Ù†ÙŠ âœ… |
| **Ø§Ù„Ø³Ø±Ø¹Ø©** | âš¡âš¡âš¡ (Ø£Ø³Ø±Ø¹!) | âš¡âš¡ | âš¡ (Ø¨Ø·ÙŠØ¡) |
| **Ø§Ù„Ø¯Ù‚Ø©** | Large v3 â­â­â­â­â­ | Large v3 â­â­â­â­â­ | Base â­â­â­ |
| **Docker Image** | ~550 MB âœ… | ~550 MB âœ… | ~2 GB âŒ |
| **Limits** | 14,400/day âœ… | ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯ ğŸ’° | ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯ âœ… |
| **Setup** | API key Ø¨Ø³ âœ… | API key + ÙÙ„ÙˆØ³ ğŸ’° | Ù…Ø¹Ù‚Ø¯ âŒ |

**Ø§Ù„Ù†ØªÙŠØ¬Ø©: Groq Ù‡Ùˆ Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„Ù…Ø¬Ø§Ù†ÙŠ!** ğŸ†

---

## ğŸ”‘ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ API Key:

### **Ø§Ù„Ø®Ø·ÙˆØ§Øª:**

1. **Ø±ÙˆØ­ Ø§Ù„Ù…ÙˆÙ‚Ø¹:**
   https://console.groq.com

2. **Sign Up:**
   - Ø§Ø¶ØºØ· "Sign In"
   - Ø§Ø³ØªØ®Ø¯Ù… Google/GitHub/Email

3. **Generate API Key:**
   - Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©: "API Keys"
   - Ø§Ø¶ØºØ· "Create API Key"
   - Ø§Ù†Ø³Ø® Ø§Ù„Ù…ÙØªØ§Ø­ (ÙŠØ¨Ø¯Ø£ Ø¨Ù€ `gsk_...`)

4. **Ø®Ù„Ø§Øµ!** ğŸ‰
   - Ù…Ø¬Ø§Ù†ÙŠ Ù„Ù„Ø£Ø¨Ø¯
   - Ø¨Ø¯ÙˆÙ† Ø¨Ø·Ø§Ù‚Ø© Ø§Ø¦ØªÙ…Ø§Ù†
   - Ø¨Ø¯ÙˆÙ† Ø§Ø´ØªØ±Ø§ÙƒØ§Øª

---

## ğŸ”§ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø§Ù„ÙƒÙˆØ¯:

### **1. Speech Service:**

Ø¥Ù†Ø´Ø§Ø¡/ØªØ¹Ø¯ÙŠÙ„ Ù…Ù„Ù: `backend/app/services/speech_service.py`

```python
from groq import Groq
import os
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class SpeechService:
    """
    Groq Whisper Service - ØªØ­ÙˆÙŠÙ„ ØµÙˆØª Ù„Ù†Øµ Ù…Ø¬Ø§Ù†ÙŠ ÙˆØ³Ø±ÙŠØ¹!
    """
    
    def __init__(self):
        # ØªÙ‡ÙŠØ¦Ø© Groq client
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            raise ValueError("GROQ_API_KEY Ù…ÙÙ‚ÙˆØ¯!")
        
        self.client = Groq(api_key=api_key)
        self.model = "whisper-large-v3"  # Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
    
    async def transcribe_audio(
        self, 
        audio_file: str,
        language: str = "ar",
        prompt: Optional[str] = None
    ) -> dict:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq Whisper
        
        Args:
            audio_file: Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ØµÙˆØª
            language: Ø§Ù„Ù„ØºØ© (ar Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©)
            prompt: Ù†Øµ Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©
        
        Returns:
            dict Ù…Ø¹ Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
        """
        try:
            with open(audio_file, "rb") as file:
                # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Groq Whisper API
                transcription = self.client.audio.transcriptions.create(
                    file=(audio_file, file.read()),
                    model=self.model,
                    language=language,
                    prompt=prompt,  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ: ÙŠØ³Ø§Ø¹Ø¯ ÙÙŠ ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚
                    response_format="verbose_json",  # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±
                    temperature=0.0  # Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
                )
            
            return {
                "text": transcription.text,
                "language": transcription.language,
                "duration": getattr(transcription, 'duration', None),
                "segments": getattr(transcription, 'segments', []),
            }
        
        except Exception as e:
            logger.error(f"ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ: {str(e)}")
            raise Exception(f"Transcription failed: {str(e)}")
    
    async def transcribe_with_timestamps(
        self,
        audio_file: str,
        language: str = "ar"
    ) -> list:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ Ù…Ø¹ timestamps
        """
        result = await self.transcribe_audio(
            audio_file=audio_file,
            language=language
        )
        
        return result.get("segments", [])


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
async def example():
    service = SpeechService()
    
    # ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ
    result = await service.transcribe_audio(
        audio_file="audio.mp3",
        language="ar"
    )
    
    print(f"Ø§Ù„Ù†Øµ: {result['text']}")
    print(f"Ø§Ù„Ù„ØºØ©: {result['language']}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(example())
```

---

## ğŸ“ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ API Endpoint:

```python
# backend/app/routers/voice.py

from fastapi import APIRouter, UploadFile, File, HTTPException
from app.services.speech_service import SpeechService
import os
import uuid
import aiofiles

router = APIRouter()
speech_service = SpeechService()

@router.post("/speech-to-text")
async def speech_to_text(
    audio: UploadFile = File(...),
    language: str = "ar"
):
    """
    ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq Whisper (Ù…Ø¬Ø§Ù†ÙŠ!)
    """
    try:
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù…Ø¤Ù‚ØªØ§Ù‹
        temp_file = f"/tmp/temp_audio/{uuid.uuid4()}.{audio.filename.split('.')[-1]}"
        
        async with aiofiles.open(temp_file, 'wb') as f:
            content = await audio.read()
            await f.write(content)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ
        result = await speech_service.transcribe_audio(
            audio_file=temp_file,
            language=language
        )
        
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        os.remove(temp_file)
        
        return {
            "success": True,
            "text": result["text"],
            "language": result["language"],
            "duration": result.get("duration")
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/speech-to-text-segments")
async def speech_to_text_with_timestamps(
    audio: UploadFile = File(...),
    language: str = "ar"
):
    """
    ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ Ù…Ø¹ timestamps
    """
    try:
        temp_file = f"/tmp/temp_audio/{uuid.uuid4()}.{audio.filename.split('.')[-1]}"
        
        async with aiofiles.open(temp_file, 'wb') as f:
            content = await audio.read()
            await f.write(content)
        
        segments = await speech_service.transcribe_with_timestamps(
            audio_file=temp_file,
            language=language
        )
        
        os.remove(temp_file)
        
        return {
            "success": True,
            "segments": segments
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## ğŸ¯ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©:

### **1. Ø§Ø³ØªØ®Ø¯Ø§Ù… Prompt:**

```python
# Ù„Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©
prompt = "Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©. Ø¥Ø²ÙŠÙƒØŒ Ø¥ÙŠÙ‡ Ø£Ø®Ø¨Ø§Ø±ÙƒØŒ Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡."

result = await service.transcribe_audio(
    audio_file="audio.mp3",
    language="ar",
    prompt=prompt  # ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚
)
```

### **2. ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª:**

```python
from pydub import AudioSegment
from pydub.effects import normalize

def preprocess_audio(input_file: str, output_file: str):
    """
    ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª Ù‚Ø¨Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
    """
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
    audio = AudioSegment.from_file(input_file)
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØª (normalize)
    audio = normalize(audio)
    
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ 16kHz mono (Ø£ÙØ¶Ù„ Ù„Ù„Ù€ Whisper)
    audio = audio.set_frame_rate(16000)
    audio = audio.set_channels(1)
    
    # Ø­ÙØ¸
    audio.export(output_file, format="wav")
    
    return output_file
```

### **3. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©:**

```python
async def transcribe_long_audio(audio_file: str) -> str:
    """
    ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ Ø·ÙˆÙŠÙ„ (Ø£ÙƒØ«Ø± Ù…Ù† 25 MB)
    """
    from pydub import AudioSegment
    
    audio = AudioSegment.from_file(audio_file)
    
    # ØªÙ‚Ø³ÙŠÙ… ÙƒÙ„ 10 Ø¯Ù‚Ø§Ø¦Ù‚
    chunk_length = 10 * 60 * 1000  # 10 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¨Ø§Ù„Ù…ÙŠÙ„ÙŠ Ø«Ø§Ù†ÙŠØ©
    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]
    
    # ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø¬Ø²Ø¡
    full_text = []
    for i, chunk in enumerate(chunks):
        chunk_file = f"/tmp/chunk_{i}.wav"
        chunk.export(chunk_file, format="wav")
        
        result = await service.transcribe_audio(chunk_file)
        full_text.append(result["text"])
        
        os.remove(chunk_file)
    
    return " ".join(full_text)
```

---

## ğŸ“Š Limits ÙˆØ§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:

### **Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©:**

```
Requests:    14,400 requests/day
Rate Limit:  30 requests/minute
Audio Size:  25 MB max per file
Duration:    ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯ (Ù„ÙƒÙ„ Ù…Ù„Ù)
```

### **Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù…Ø«Ù„:**

1. **Cache Ø§Ù„Ù†ØªØ§Ø¦Ø¬:**
   ```python
   # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ database
   # Ù„ØªØ¬Ù†Ø¨ Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†ÙØ³ Ø§Ù„Ù…Ù„Ù
   ```

2. **Rate Limiting:**
   ```python
   import asyncio
   from collections import deque
   
   class RateLimiter:
       def __init__(self, max_per_minute=30):
           self.max_per_minute = max_per_minute
           self.requests = deque()
       
       async def wait_if_needed(self):
           now = asyncio.get_event_loop().time()
           
           # Ø­Ø°Ù Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ø£ÙƒØ«Ø± Ù…Ù† Ø¯Ù‚ÙŠÙ‚Ø©)
           while self.requests and self.requests[0] < now - 60:
               self.requests.popleft()
           
           # Ø§Ù†ØªØ¸Ø± Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ù„Ù„Ø­Ø¯
           if len(self.requests) >= self.max_per_minute:
               sleep_time = 60 - (now - self.requests[0])
               await asyncio.sleep(sleep_time)
           
           self.requests.append(now)
   ```

3. **ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„ÙØ§Øª:**
   ```python
   # Ø§Ø³ØªØ®Ø¯Ù… opus Ø£Ùˆ mp3 Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† wav
   audio.export("output.opus", format="opus", bitrate="32k")
   ```

---

## ğŸ” Environment Variables:

```env
# Groq API (Ù„Ù„Ù€ Whisper - Ù…Ø¬Ø§Ù†ÙŠ!)
GROQ_API_KEY=gsk_xxxxx

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Whisper
WHISPER_MODEL=whisper-large-v3
WHISPER_LANGUAGE=ar
WHISPER_PROMPT="Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©"

# Directories
TEMP_AUDIO_DIR=/tmp/temp_audio
```

---

## ğŸ’¡ Ù…Ø«Ø§Ù„ ÙƒØ§Ù…Ù„ - Chat Bot:

```python
from fastapi import FastAPI, UploadFile, File
from app.services.speech_service import SpeechService
from app.services.tts_service import TTSService
from app.services.ai_service import AIService
import uuid

app = FastAPI()

speech_service = SpeechService()
tts_service = TTSService()
ai_service = AIService()

@router.post("/voice-chat")
async def voice_chat(audio: UploadFile = File(...)):
    """
    Ù…Ø­Ø§Ø¯Ø«Ø© ØµÙˆØªÙŠØ© ÙƒØ§Ù…Ù„Ø©:
    ØµÙˆØª â†’ Ù†Øµ â†’ AI â†’ Ù†Øµ â†’ ØµÙˆØª
    """
    try:
        # 1. Ø­ÙØ¸ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¯Ø®Ù„
        input_file = f"/tmp/input_{uuid.uuid4()}.mp3"
        with open(input_file, "wb") as f:
            f.write(await audio.read())
        
        # 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ (Groq Whisper - Ù…Ø¬Ø§Ù†ÙŠ!)
        transcription = await speech_service.transcribe_audio(
            audio_file=input_file,
            language="ar"
        )
        user_text = transcription["text"]
        
        # 3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¯ Ù…Ù† AI (OpenRouter - Ø±Ø®ÙŠØµ)
        ai_response = await ai_service.get_response(user_text)
        
        # 4. ØªØ­ÙˆÙŠÙ„ Ø±Ø¯ AI Ù„ØµÙˆØª (Edge TTS - Ù…Ø¬Ø§Ù†ÙŠ!)
        output_file = f"/tmp/output_{uuid.uuid4()}.mp3"
        await tts_service.text_to_speech(
            text=ai_response,
            output_file=output_file
        )
        
        # 5. Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ØµÙˆØª
        from fastapi.responses import FileResponse
        return FileResponse(
            output_file,
            media_type="audio/mpeg",
            headers={
                "X-User-Text": user_text,
                "X-AI-Response": ai_response
            }
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## ğŸ¯ Ø§Ù„Ø®Ù„Ø§ØµØ©:

### **Ø§Ù„Ø­Ù„ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„:**

```
Voice Input (User)
    â†“
Groq Whisper (Ù…Ø¬Ø§Ù†ÙŠ!) â†’ Text
    â†“
OpenRouter/Gemma (Ø±Ø®ÙŠØµ!) â†’ AI Response
    â†“
Edge TTS (Ù…Ø¬Ø§Ù†ÙŠ!) â†’ Voice Output
    â†“
Voice Response (User hears)
```

### **Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ø´Ù‡Ø±ÙŠØ©:**

```
Groq Whisper:   Ù…Ø¬Ø§Ù†ÙŠ âœ…
Edge TTS:       Ù…Ø¬Ø§Ù†ÙŠ âœ…
OpenRouter:     ~$0.14/Ø´Ù‡Ø± (1000 Ù…Ø­Ø§Ø¯Ø«Ø©)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹:       ~$0.14/Ø´Ù‡Ø± ÙÙ‚Ø·!
```

**Ø£Ø±Ø®Øµ Ø­Ù„ Ù…Ù…ÙƒÙ†!** ğŸ‰

---

## ğŸ“š Ø±ÙˆØ§Ø¨Ø· Ù…ÙÙŠØ¯Ø©:

- [Groq Console](https://console.groq.com)
- [Groq Docs](https://console.groq.com/docs)
- [Groq Python SDK](https://github.com/groq/groq-python)
- [Whisper Documentation](https://platform.openai.com/docs/guides/speech-to-text)

---

## âœ… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:

```
âœ… Whisper Ù…Ø¬Ø§Ù†ÙŠ 100%
âœ… TTS Ù…Ø¬Ø§Ù†ÙŠ 100%
âœ… Ø£Ø³Ø±Ø¹ Ù…Ù† OpenAI
âœ… Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹
âœ… ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©
âœ… Docker Image ØµØºÙŠØ± (~550 MB)
âœ… Ø³Ù‡Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
âœ… Ø¨Ø¯ÙˆÙ† Ø§Ø´ØªØ±Ø§ÙƒØ§Øª
```

**Ù…Ø¨Ø±ÙˆÙƒ! Ø¯Ù„ÙˆÙ‚ØªÙŠ ÙƒÙ„ Ø­Ø§Ø¬Ø© Ù…Ø¬Ø§Ù†ÙŠØ©!** ğŸ‰ğŸ¤ğŸ‡ªğŸ‡¬
